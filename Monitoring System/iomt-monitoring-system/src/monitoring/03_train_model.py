"""
Script 03: Train Alert Prioritization Model
Random Forest Classifier for ~90% accuracy
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import os

print("="*75)
print("ğŸ¤– TRAINING ALERT PRIORITIZATION MODEL")
print("="*75)

# Load processed data
print("\nğŸ”„ Loading processed data...")
X_train = pd.read_csv('../../data/processed/X_train.csv')
X_test = pd.read_csv('../../data/processed/X_test.csv')
y_train = pd.read_csv('../../data/processed/y_train.csv').values.ravel()
y_test = pd.read_csv('../../data/processed/y_test.csv').values.ravel()

print(f"   âœ… Training samples: {len(X_train):,}")
print(f"   âœ… Testing samples: {len(X_test):,}")
print(f"   âœ… Features: {len(X_train.columns)}")

# Create Random Forest model
print("\nğŸ”„ Creating Random Forest Classifier...")
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=20,
    min_samples_split=10,
    min_samples_leaf=4,
    random_state=42,
    n_jobs=-1,
    verbose=1
)

# Train model
print("\nğŸš€ Training model...")
model.fit(X_train, y_train)
print("   âœ… Training complete!")

# Make predictions
print("\nğŸ”® Making predictions on test set...")
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"\nğŸ¯ Test Accuracy: {accuracy*100:.2f}%")

# Classification report
print("\nğŸ“Š Classification Report:")
print(classification_report(y_test, y_pred))

# Confusion matrix
print("\nğŸ“Š Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred, labels=['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'INFO'])
print(cm)

# Visualize confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'INFO'],
            yticklabels=['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'INFO'])
plt.title(f'Confusion Matrix - Accuracy: {accuracy*100:.2f}%', fontsize=14, fontweight='bold')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.tight_layout()
plt.savefig('../../results/04_confusion_matrix.png', dpi=300)
print("\n   âœ… Saved: results/04_confusion_matrix.png")

# Feature importance
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nğŸ“Š Top 10 Most Important Features:")
print(feature_importance.head(10).to_string(index=False))

# Visualize feature importance
plt.figure(figsize=(10, 8))
feature_importance.head(15).plot(x='feature', y='importance', kind='barh', color='skyblue', legend=False)
plt.title('Top 15 Feature Importances', fontsize=14, fontweight='bold')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('../../results/05_feature_importance.png', dpi=300)
print("   âœ… Saved: results/05_feature_importance.png")

# Save model
print("\nğŸ’¾ Saving trained model...")
with open('../../models/alert_prioritization_model.pkl', 'wb') as f:
    pickle.dump(model, f)
print("   âœ… Saved: models/alert_prioritization_model.pkl")

# Save metrics
metrics = {
    'accuracy': accuracy,
    'training_samples': len(X_train),
    'testing_samples': len(X_test),
    'features': list(X_train.columns)
}

with open('../../models/model_metrics.pkl', 'wb') as f:
    pickle.dump(metrics, f)
print("   âœ… Saved: models/model_metrics.pkl")

print("\n" + "="*75)
print("âœ… MODEL TRAINING COMPLETE!")
print("="*75)
print(f"\nğŸ¯ Final Accuracy: {accuracy*100:.2f}%")
print("ğŸ“ Check 'results' folder for visualizations!")
print("ğŸ“ Check 'models' folder for saved model!\n")