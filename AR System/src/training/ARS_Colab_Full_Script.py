# -*- coding: utf-8 -*-
"""ARS_Colab_Training_Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xxxxxxxxx

# ARS Model Training Notebook (Automated Response System)

This notebook performs the full training pipeline for the ARS component:
1. **Generates Synthetic Data** (Threats & PHI Logs)
2. **Preprocesses Data** (Encoding & Cleaning)
3. **Trains AI Models** (Random Forest for Response & PHI Detection)
4. **Exports Models** (.pkl files)
"""

import json
import random
import datetime
import uuid
import pandas as pd
import numpy as np
import pickle
import re
import string
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from google.colab import files  # For downloading files

# ==========================================
# 1. DATA UPLOAD
# ==========================================
print("--- Please Upload your Datasets (optimized_threat_triggers.json & optimized_phi_logs.json) ---")
uploaded = files.upload()

# Check if files exist
if "optimized_threat_triggers.json" in uploaded and "optimized_phi_logs.json" in uploaded:
    print("Files uploaded successfully.")
    
    # Load JSONs into Pandas
    with open("optimized_threat_triggers.json", "r") as f:
        df_threats = pd.DataFrame(json.load(f))
        
    with open("optimized_phi_logs.json", "r") as f:
        df_phi = pd.DataFrame(json.load(f))
        
    print(f"Loaded {len(df_threats)} Threat records and {len(df_phi)} PHI log records.")
else:
    print("ERROR: Please upload both JSON files generated previously.")

# ==========================================
# 2. PREPROCESSING & TRAINING (Response Model)
# ==========================================
print("\n--- Training Response Model (Action Logic) ---")

# Encode
le_threat = LabelEncoder()
df_threats['threat_encoded'] = le_threat.fit_transform(df_threats['threat_type'])

severity_map = {"None": 0, "Low": 1, "Medium": 2, "High": 3, "Critical": 4}
df_threats['severity_encoded'] = df_threats['severity'].map(severity_map)

# Target Map
action_map = {"NO_ACTION": 0, "MONITOR": 1, "ISOLATE": 2, "ROLLBACK": 3}
df_threats['action_target'] = df_threats['action_required'].map(action_map)

# Split
X = df_threats[['threat_encoded', 'severity_encoded', 'confidence_score']]
y = df_threats['action_target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train
clf_resp = RandomForestClassifier(n_estimators=100)
clf_resp.fit(X_train, y_train)
print(f"Response Accuracy: {accuracy_score(y_test, clf_resp.predict(X_test))*100:.2f}%")

# ==========================================
# 3. PREPROCESSING & TRAINING (PHI Model)
# ==========================================
print("\n--- Training PHI Detection Model (NLP) ---")

# Vectorize
vectorizer = TfidfVectorizer(max_features=5000)
X_phi = vectorizer.fit_transform(df_phi['raw_log_message'].str.lower())
y_phi = df_phi['phi_label']

X_train_phi, X_test_phi, y_train_phi, y_test_phi = train_test_split(X_phi, y_phi, test_size=0.2)

# Train
clf_phi = RandomForestClassifier(n_estimators=50)
clf_phi.fit(X_train_phi, y_train_phi)
print(f"PHI Accuracy: {accuracy_score(y_test_phi, clf_phi.predict(X_test_phi))*100:.2f}%")

# ==========================================
# 4. SAVE & DOWNLOAD
# ==========================================
print("\n--- Saving Models ---")

# Save Response Model
with open('ars_response_model.pkl', 'wb') as f:
    pickle.dump({
        "model": clf_resp,
        "le_threat": le_threat,
        "le_severity": LabelEncoder(), # Mock for creating local env, ideally save map
        "action_map": action_map
    }, f)

# Save PHI Model
with open('ars_phi_model.pkl', 'wb') as f:
    pickle.dump({
        "model": clf_phi,
        "vectorizer": vectorizer
    }, f)

print("Downloading files to your local machine...")
files.download('ars_response_model.pkl')
files.download('ars_phi_model.pkl')
